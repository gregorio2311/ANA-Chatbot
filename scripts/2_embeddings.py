"""
GENERADOR DE EMBEDDINGS - ANA-CHATBOT
====================================

Este script genera embeddings sem√°nticos a partir de fragmentos de texto de documentos
de anatom√≠a. Es el segundo paso del pipeline de procesamiento.

FUNCIONALIDADES:
- Carga fragmentos de texto desde metadatos JSON
- Genera embeddings usando modelo BAAI/bge-large-en-v1.5
- Valida fragmentos antes del procesamiento
- Proporciona estad√≠sticas detalladas por libro
- Guarda embeddings en formato pickle con metadatos

REQUISITOS:
- Archivo fragmentos_metadata.json generado por frag.py
- Carpeta fragmentos/ con archivos de texto
- GPU recomendada para mejor rendimiento (opcional)

USO:
    python scripts/embeddings.py

FLUJO DE TRABAJO:
    1. Procesar documentos ‚Üí frag.py (genera fragmentos_metadata.json)
    2. Generar embeddings ‚Üí embeddings.py (este script)
    3. Subir a Pinecone ‚Üí pinecone_u.py
    4. Usar chatbot ‚Üí consulta.py

EJEMPLO DE SALIDA:
    ‚úÖ GPU detectada, se usar√° para crear embeddings.
    üîß GPU: NVIDIA GeForce RTX 3080
    üîÑ Cargando modelo de embeddings...
    üìÅ Cargando metadatos de fragmentos...
    üìÑ Encontrados 150 fragmentos para procesar
    üìö Fragmentos v√°lidos por libro:
       - G_A_S_4_E: 75 fragmentos, 37500 palabras
       - LIBRO_IFSSA: 75 fragmentos, 37500 palabras
    üß† Generando embeddings...
    üíæ Guardando embeddings...
    ‚úÖ Embeddings guardados en embeddings.pkl
    üìä Total de fragmentos procesados: 150
    üî¢ Dimensiones de embeddings: (150, 1024)

DEPENDENCIAS:
- sentence-transformers: Para generar embeddings sem√°nticos
- torch: Framework de machine learning
- pickle: Para serializar embeddings
- json: Para cargar metadatos

AUTOR: Equipo de desarrollo ANA-Chatbot
FECHA: 2024
"""

# 1_crear_embeddings

from sentence_transformers import SentenceTransformer
import os
import pickle
import sys
import torch
import json

def crear_embeddings():
    """
    Funci√≥n principal que genera embeddings sem√°nticos para todos los fragmentos.
    
    Esta funci√≥n:
    1. Verifica disponibilidad de GPU
    2. Carga el modelo de embeddings
    3. Valida archivos de entrada
    4. Procesa fragmentos de texto
    5. Genera embeddings sem√°nticos
    6. Guarda resultados con metadatos
    
    Returns:
        bool: True si el proceso fue exitoso, False si hubo errores
        
    Example:
        >>> success = crear_embeddings()
        >>> if success:
        >>>     print("Embeddings generados exitosamente")
    """
    try:
        # Obtener la ruta del directorio ra√≠z del proyecto
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(script_dir)
        
        # Verificar GPU
        if not torch.cuda.is_available():
            print("‚ö†Ô∏è Advertencia: No se detect√≥ GPU, se usar√° CPU. Esto ser√° m√°s lento.")
        else:
            print("‚úÖ GPU detectada, se usar√° para crear embeddings.")
            print(f"üîß GPU: {torch.cuda.get_device_name(0)}")
        
        # Cargar modelo
        print("üîÑ Cargando modelo de embeddings...")
        model = SentenceTransformer("BAAI/bge-large-en-v1.5")
        
        # Verificar que existe el archivo de metadatos
        metadata_file = os.path.join(project_root, "fragmentos_metadata.json")
        if not os.path.exists(metadata_file):
            print(f"‚ùå Error: El archivo '{metadata_file}' no existe")
            print("üí° Ejecuta primero el script frag.py para generar los fragmentos")
            return False
        
        # Cargar metadatos
        print("üìÅ Cargando metadatos de fragmentos...")
        with open(metadata_file, "r", encoding="utf-8") as f:
            fragmentos = json.load(f)
        
        if not fragmentos:
            print(f"‚ùå Error: No se encontraron fragmentos en '{metadata_file}'")
            return False
            
        print(f"üìÑ Encontrados {len(fragmentos)} fragmentos para procesar")
        
        # Verificar que los archivos de fragmentos existen
        carpeta = os.path.join(project_root, "data", "fragmentos")
        if not os.path.exists(carpeta):
            print(f"‚ùå Error: La carpeta '{carpeta}' no existe")
            return False
        
        # Filtrar fragmentos v√°lidos y cargar textos
        fragmentos_validos = []
        for fragmento in fragmentos:
            archivo_fragmento = f"{fragmento['id']}_{fragmento['palabras']}palabras.txt"
            ruta_completa = os.path.join(carpeta, archivo_fragmento)
            
            if os.path.exists(ruta_completa):
                try:
                    with open(ruta_completa, "r", encoding="utf-8") as f:
                        texto = f.read().strip()
                        if texto:  # Solo agregar si no est√° vac√≠o
                            fragmento["texto"] = texto
                            fragmentos_validos.append(fragmento)
                except Exception as e:
                    print(f"‚ö†Ô∏è Error leyendo {archivo_fragmento}: {e}")
                    continue
            else:
                print(f"‚ö†Ô∏è Archivo no encontrado: {archivo_fragmento}")
        
        if not fragmentos_validos:
            print("‚ùå Error: No se pudieron leer fragmentos v√°lidos")
            return False
        
        # Estad√≠sticas por libro
        libros_stats = {}
        for fragmento in fragmentos_validos:
            libro = fragmento["libro"]
            if libro not in libros_stats:
                libros_stats[libro] = {"fragmentos": 0, "palabras": 0}
            libros_stats[libro]["fragmentos"] += 1
            libros_stats[libro]["palabras"] += fragmento["palabras"]
        
        print(f"\nüìö Fragmentos v√°lidos por libro:")
        for libro, stats in libros_stats.items():
            print(f"   - {libro}: {stats['fragmentos']} fragmentos, {stats['palabras']} palabras")
        
        # Generar embeddings
        print("\nüß† Generando embeddings...")
        texts = [f["texto"] for f in fragmentos_validos]
        embeddings = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)
        
        # Guardar embeddings y metadatos
        print("üíæ Guardando embeddings...")
        with open("embeddings.pkl", "wb") as f:
            pickle.dump({
                "fragmentos": fragmentos_validos, 
                "embeddings": embeddings,
                "modelo": "BAAI/bge-large-en-v1.5",
                "total_fragmentos": len(fragmentos_validos),
                "libros": list(libros_stats.keys()),
                "estadisticas_libros": libros_stats
            }, f)
        
        print(f"‚úÖ Embeddings guardados en embeddings.pkl")
        print(f"üìä Total de fragmentos procesados: {len(fragmentos_validos)}")
        print(f"üî¢ Dimensiones de embeddings: {embeddings.shape}")
        print(f"üìö Libros incluidos: {', '.join(libros_stats.keys())}")
        return True
        
    except Exception as e:
        print(f"‚ùå Error inesperado: {e}")
        return False

if __name__ == "__main__":
    crear_embeddings()
