"""
GENERADOR DE EMBEDDINGS MEJORADO - ANA-CHATBOT
=============================================

Este script genera embeddings sem√°nticos a partir de fragmentos mejorados
de documentos de anatom√≠a. Trabaja con el nuevo formato JSON estructurado.

FUNCIONALIDADES:
- Carga fragmentos desde fragmentos_mejorados.json
- Genera embeddings usando modelo BAAI/bge-m3
- Valida fragmentos antes del procesamiento
- Proporciona estad√≠sticas detalladas por fuente y secci√≥n
- Guarda embeddings en formato pickle con metadatos mejorados

REQUISITOS:
- Archivo fragmentos_mejorados.json generado por 1_frag_mejorado.py
- GPU recomendada para mejor rendimiento (opcional)

USO:
    python scripts/2_embeddings_mejorado.py

FLUJO DE TRABAJO:
    1. Procesar documentos ‚Üí 1_frag_mejorado.py (genera fragmentos_mejorados.json)
    2. Generar embeddings ‚Üí 2_embeddings_mejorado.py (este script)
    3. Subir a Pinecone ‚Üí 3_pinecone_u.py
    4. Usar chatbot ‚Üí 4_consulta.py

EJEMPLO DE SALIDA:
    ‚úÖ GPU detectada, se usar√° para crear embeddings.
    üîß GPU: NVIDIA GeForce RTX 3080
    üîÑ Cargando modelo de embeddings...
    üìÅ Cargando metadatos de fragmentos mejorados...
    üìÑ Encontrados 250 fragmentos para procesar
    üìö Fragmentos v√°lidos por fuente:
       - Diapositivas - Sistema Muscular: 45 fragmentos, 22500 palabras
       - Diapositivas - Sistema Esquel√©tico: 52 fragmentos, 26000 palabras
       - Complemento Anatom√≠a Funcional Humana: 153 fragmentos, 76500 palabras
    üß† Generando embeddings...
    üíæ Guardando embeddings...
    ‚úÖ Embeddings guardados en embeddings_mejorados.pkl
    üìä Total de fragmentos procesados: 250
    üî¢ Dimensiones de embeddings: (250, 1024)

DEPENDENCIAS:
- sentence-transformers: Para generar embeddings sem√°nticos
- torch: Framework de machine learning
- pickle: Para serializar embeddings
- json: Para cargar metadatos

AUTOR: Equipo de desarrollo ANA-Chatbot
FECHA: 2024
"""

from sentence_transformers import SentenceTransformer
import os
import pickle
import sys
import torch
import json
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def crear_embeddings_mejorados():
    """
    Funci√≥n principal que genera embeddings sem√°nticos para todos los fragmentos mejorados.
    
    Esta funci√≥n:
    1. Verifica disponibilidad de GPU
    2. Carga el modelo de embeddings
    3. Valida archivos de entrada
    4. Procesa fragmentos de texto desde JSON mejorado
    5. Genera embeddings sem√°nticos
    6. Guarda resultados con metadatos mejorados
    
    Returns:
        bool: True si el proceso fue exitoso, False si hubo errores
        
    Example:
        >>> success = crear_embeddings_mejorados()
        >>> if success:
        >>>     print("Embeddings mejorados generados exitosamente")
    """
    try:
        # Obtener la ruta del directorio ra√≠z del proyecto
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(script_dir)
        
        # Verificar GPU
        if not torch.cuda.is_available():
            logger.warning("‚ö†Ô∏è Advertencia: No se detect√≥ GPU, se usar√° CPU. Esto ser√° m√°s lento.")
        else:
            logger.info("‚úÖ GPU detectada, se usar√° para crear embeddings.")
            logger.info(f"üîß GPU: {torch.cuda.get_device_name(0)}")
        
        # Cargar modelo
        logger.info("üîÑ Cargando modelo de embeddings...")
        model = SentenceTransformer("BAAI/bge-m3")
        
        # Verificar que existe el archivo de metadatos mejorados
        metadata_file = os.path.join(project_root, "data", "fragmentos_mejorados.json")
        if not os.path.exists(metadata_file):
            logger.error(f"‚ùå Error: El archivo '{metadata_file}' no existe")
            logger.info("üí° Ejecuta primero el script 1_frag_mejorado.py para generar los fragmentos")
            return False
        
        # Cargar metadatos mejorados
        logger.info("üìÅ Cargando metadatos de fragmentos mejorados...")
        with open(metadata_file, "r", encoding="utf-8") as f:
            fragmentos = json.load(f)
        
        if not fragmentos:
            logger.error(f"‚ùå Error: No se encontraron fragmentos en '{metadata_file}'")
            return False
            
        logger.info(f"üìÑ Encontrados {len(fragmentos)} fragmentos para procesar")
        
        # Validar que los fragmentos tienen el texto completo
        fragmentos_validos = []
        for fragmento in fragmentos:
            if "text" in fragmento and fragmento["text"].strip():
                fragmentos_validos.append(fragmento)
            else:
                logger.warning(f"‚ö†Ô∏è Fragmento {fragmento.get('id', 'desconocido')} no tiene texto v√°lido")
        
        if not fragmentos_validos:
            logger.error("‚ùå Error: No se encontraron fragmentos con texto v√°lido")
            return False
        
        # Estad√≠sticas por fuente
        fuentes_stats = {}
        secciones_stats = {}
        
        for fragmento in fragmentos_validos:
            fuente = fragmento["source"]
            seccion = fragmento["section"]
            palabras = fragmento["metadata"]["word_count"]
            
            # Estad√≠sticas por fuente
            if fuente not in fuentes_stats:
                fuentes_stats[fuente] = {"fragmentos": 0, "palabras": 0, "secciones": set()}
            fuentes_stats[fuente]["fragmentos"] += 1
            fuentes_stats[fuente]["palabras"] += palabras
            fuentes_stats[fuente]["secciones"].add(seccion)
            
            # Estad√≠sticas por secci√≥n
            if seccion not in secciones_stats:
                secciones_stats[seccion] = {"fragmentos": 0, "palabras": 0, "fuentes": set()}
            secciones_stats[seccion]["fragmentos"] += 1
            secciones_stats[seccion]["palabras"] += palabras
            secciones_stats[seccion]["fuentes"].add(fuente)
        
        logger.info(f"\nüìö Fragmentos v√°lidos por fuente:")
        for fuente, stats in fuentes_stats.items():
            logger.info(f"   - {fuente}: {stats['fragmentos']} fragmentos, {stats['palabras']} palabras, {len(stats['secciones'])} secciones")
        
        logger.info(f"\nüìñ Fragmentos v√°lidos por secci√≥n:")
        for seccion, stats in secciones_stats.items():
            logger.info(f"   - {seccion}: {stats['fragmentos']} fragmentos, {stats['palabras']} palabras, {len(stats['fuentes'])} fuentes")
        
        # Generar embeddings usando texto del JSON
        logger.info("\nüß† Generando embeddings...")
        texts = [f["text"] for f in fragmentos_validos]
        embeddings = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)
        
        # Preparar metadatos mejorados para guardar
        metadatos_mejorados = {
            "fragmentos": fragmentos_validos, 
            "embeddings": embeddings,
            "modelo": "BAAI/bge-m3",
            "total_fragmentos": len(fragmentos_validos),
            "fuentes": list(fuentes_stats.keys()),
            "secciones": list(secciones_stats.keys()),
            "estadisticas_fuentes": {
                fuente: {
                    "fragmentos": stats["fragmentos"],
                    "palabras": stats["palabras"],
                    "secciones": list(stats["secciones"])
                } for fuente, stats in fuentes_stats.items()
            },
            "estadisticas_secciones": {
                seccion: {
                    "fragmentos": stats["fragmentos"],
                    "palabras": stats["palabras"],
                    "fuentes": list(stats["fuentes"])
                } for seccion, stats in secciones_stats.items()
            }
        }
        
        # Guardar embeddings y metadatos mejorados
        logger.info("üíæ Guardando embeddings...")
        output_file = "embeddings_mejorados.pkl"
        with open(output_file, "wb") as f:
            pickle.dump(metadatos_mejorados, f)
        
        logger.info(f"‚úÖ Embeddings guardados en {output_file}")
        logger.info(f"üìä Total de fragmentos procesados: {len(fragmentos_validos)}")
        logger.info(f"üî¢ Dimensiones de embeddings: {embeddings.shape}")
        logger.info(f"üìö Fuentes incluidas: {', '.join(fuentes_stats.keys())}")
        logger.info(f"üìñ Secciones incluidas: {', '.join(secciones_stats.keys())}")
        
        # Mostrar estad√≠sticas detalladas
        logger.info(f"\nüìà Estad√≠sticas detalladas:")
        logger.info(f"   - Promedio de palabras por fragmento: {sum(f['metadata']['word_count'] for f in fragmentos_validos) / len(fragmentos_validos):.1f}")
        logger.info(f"   - Fragmento m√°s largo: {max(f['metadata']['word_count'] for f in fragmentos_validos)} palabras")
        logger.info(f"   - Fragmento m√°s corto: {min(f['metadata']['word_count'] for f in fragmentos_validos)} palabras")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error inesperado: {e}")
        return False

if __name__ == "__main__":
    success = crear_embeddings_mejorados()
    if not success:
        sys.exit(1) 